{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitbaseconda75bb0402ed2244d79c216a23b72cd86d",
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "import argparse\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import darknet\n",
    "import darknet_images\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# LOAD and CONFIG\n",
    "txt_input = \"../FIRELOC_DATA/train.txt\"\n",
    "batch_size = True\n",
    "weights = \"../FIRELOC_DATA/yolov4.weights\"\n",
    "dont_show = True\n",
    "ext_output = True\n",
    "save_labels = True\n",
    "config_file = \"cfg/yolov4.cfg\"\n",
    "data_file = \"cfg/coco.data\"\n",
    "thresh = 0.25\n",
    "\n",
    "images = darknet_images.load_images(txt_input)\n",
    "image_name = images[0]\n",
    "network, class_names, class_colors = darknet.load_network(\n",
    "        config_file,\n",
    "        data_file,\n",
    "        weights,\n",
    "        batch_size\n",
    ")\n",
    "\n",
    "# pick class index out of the top 5 classes\n",
    "# in the dog.jpg example:\n",
    "# 0 is plant\n",
    "# 1 is truck\n",
    "# 2 is bicycle\n",
    "# 3 is dog\n",
    "# how many samples to use in explain_instance\n",
    "num_samples = 2000\n",
    "# how many features maximum can be used in the explanation (default is 100000)\n",
    "num_features = 100000000\n",
    "\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------\n",
    "\n",
    "width = darknet.network_width(network)\n",
    "height = darknet.network_height(network)\n",
    "image = cv2.imread(image_name)\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "image_resized = cv2.resize(image_rgb, (width, height),\n",
    "                            interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "\n",
    "\n",
    "def grey_out(image, x, y, w, h):\n",
    "    # input: ndarray returned by imread, height and width\n",
    "    #Create an array of object rect which represents the region of interest\n",
    "    rect = [[x-w/2,y+h/2], [x-w/2,y-h/2], [x+w/2,y-h/2],[x+w/2,y+h/2]]\n",
    "    mask = np.array([rect], dtype=np.int32)\n",
    "\n",
    "    #Create a new array filled with zeros, size equal to size of the image to be filtered\n",
    "    image2 = np.zeros((width, height), np.int8)\n",
    "\n",
    "    cv2.fillPoly(image2, [mask],255)    \n",
    "    maskimage2 = cv2.inRange(image2, 1, 255)\n",
    "    out = cv2.bitwise_and(image, image, mask=maskimage2)\n",
    "    #cv2.imshow(\"img\",out)\n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "# so funciona para uma imagem\n",
    "def funcao_classificacao_lime(image_numpy):\n",
    "\n",
    "    probabilities = np.zeros((len(image_numpy), len(class_names)))\n",
    "    for i in range(len(image_numpy)):\n",
    "        img = image_numpy[i]\n",
    "        image, detections = darknet_images.image_detection_lime(\n",
    "                img, network, class_names,\n",
    "                class_colors, thresh\n",
    "                )\n",
    "\n",
    "        if save_labels:\n",
    "            darknet_images.save_annotations(image_name, image, detections, class_names)\n",
    "        #darknet.print_detections(detections, ext_output)\n",
    "        if not dont_show:\n",
    "            cv2.imshow('Inference', image)\n",
    "            if cv2.waitKey() & 0xFF == ord('q'):\n",
    "                return\n",
    "\n",
    "        with open(\"probabilityArray.txt\",\"r\") as prob_array:\n",
    "            lines = [float(line.rstrip()) for line in prob_array]\n",
    "            probabilities[i] = lines\n",
    "    return probabilities\n",
    "\n",
    "\n",
    "def get_most_confident_bbox(class_name):\n",
    "    # First run through Yolo to check if\n",
    "    image_original, detections = darknet_images.image_detection(\n",
    "                image_name, network, class_names,\n",
    "                class_colors, thresh\n",
    "                )\n",
    "    darknet.print_detections(detections, ext_output)\n",
    "    # take the detection that had the most confidence and write the coordinates to a txt file\n",
    "    #detections is a list of tuples (class, confidence,(coordinates))\n",
    "    picked_class = -1\n",
    "    for i in range(len(detections)):\n",
    "        _tuple = detections[i]\n",
    "        if _tuple[0] == class_name:\n",
    "            coordinates = _tuple[2]\n",
    "            with open(\"coordinates.txt\",\"w+\") as coord_file:\n",
    "                # we convert the coordinates to relative because that's how it is used in the C files\n",
    "                coordinates_rel = darknet_images.convert2relative(image_original,coordinates)\n",
    "                for _coord in coordinates_rel:\n",
    "                    coord_file.write(str(_coord)+\"\\n\")\n",
    "                picked_class = i\n",
    "            break\n",
    "    return picked_class, detections\n",
    "\n",
    "\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class_name = 'dog'  \n",
    "picked_class, coordinates = get_most_confident_bbox(class_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# pass the image, the height and width\n",
    "greyed_out_image = grey_out(image_resized, coordinates[picked_class][2][0], coordinates[picked_class][2][1],coordinates[picked_class][2][2], coordinates[picked_class][2][3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from lime import lime_image\n",
    "#Objeto do tipo LimeImageExplainer\n",
    "explainer = lime_image.LimeImageExplainer()\n",
    "#Objeto do tipo ImageExplanation\n",
    "explanation = explainer.explain_instance(np.array(greyed_out_image), \n",
    "                                         funcao_classificacao_lime, # classification function\n",
    "                                         top_labels=5, \n",
    "                                         hide_color=0, \n",
    "                                         num_samples=num_samples,\n",
    "                                         num_features=num_features) # number of images that will be sent to classification function\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.segmentation import mark_boundaries\n",
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0],\\\n",
    "    positive_only=False, num_features=1, hide_rest=False)\n",
    "img_boundry2 = mark_boundaries(temp/255.0, mask)\n",
    "plt.imshow(img_boundry2)\n",
    "#mostrar centros das bounding boxes \n",
    "plt.scatter([coordinates[0][2][0], coordinates[1][2][0], coordinates[2][2][0], coordinates[3][2][0]],\\\n",
    "        [coordinates[0][2][1], coordinates[1][2][1], coordinates[2][2][1], coordinates[3][2][1]],\\\n",
    "        marker='o', color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_img(img, new_filename, coordinates, picked_class):\n",
    "    [center_x, center_y, width, height] = [coord for coord in coordinates[picked_class][2]]\n",
    "    top_left_x = round(center_x - width/2)\n",
    "    top_left_y = round(center_y - height/2)\n",
    "    crop_img = img[top_left_y:top_left_y+height, top_left_x:top_left_x+width]\n",
    "    plt.imshow(crop_img)\n",
    "    plt.show()\n",
    "    # guardo a nova imagem num ficheiro\n",
    "    cv2.imwrite(new_filename,crop_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_img(img_boundry2, \"explanationHere.jpg\", coordinates, picked_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}